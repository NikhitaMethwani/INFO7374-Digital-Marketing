{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian Low-rank Matrix Completion algorithm on Movielens dataset\n",
    "Riemannian Low-rank Matrix Completion (RLRMC) is a matrix factorization based (vanilla) matrix completion algorithm that solves the optimization problem using Riemannian conjugate gradients algorithm (Absil et al., 2008). RLRMC is based on the works by Jawanpuria and Mishra (2018) and Mishra et al. (2013).\n",
    "\n",
    "The ratings matrix of movies (items) and users is modeled as a low-rank matrix. Let the number of movies be  ùëë  and the number of users be  ùëá . RLRMC algorithm assumes that the ratings matrix  ùëÄ  (of size  ùëë√óùëá ) is partially known. The entry at  ùëÄ(ùëñ,ùëó)  represents the rating given by the  ùëó -th user to the  ùëñ -th movie. RLRMC learns matrix  ùëÄ  as  ùëÄ=ùêøùëÖ‚ä§ , where  ùêø  is a  ùëë√óùëü  matrix and  ùëÖ  is a  ùëá√óùëü  matrix. Here,  ùëü  is the rank hyper-parameter which needs to be provided to the RLRMC algorithm. Typically, it is assumed that  ùëü‚â™ùëë,ùëá . The optimization problem is solved iteratively using the the Riemannian conjugate gradients algorithm. The Riemannian optimization framework generalizes a range of Euclidean first- and second-order algorithms such as conjugate gradients, trust-regions, among others, to Riemannian manifolds. A detailed exposition of the Riemannian optimization framework can be found in Absil et al. (2008).\n",
    "\n",
    "This notebook provides an example of how to utilize and evaluate RLRMC implementation in reco_utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../reco_utils/recommender/rlrmc/\")\n",
    "\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.recommender.rlrmc.RLRMCdataset import RLRMCdataset \n",
    "from reco_utils.recommender.rlrmc.RLRMCalgorithm import RLRMCalgorithm \n",
    "# Pymanopt installation is required via\n",
    "# pip install pymanopt \n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    rmse, mae\n",
    ")\n",
    "from reco_utils.dataset.python_splitters import (\n",
    "    python_random_split, \n",
    "    python_chrono_split, \n",
    "    python_stratified_split\n",
    ")\n",
    "\n",
    "# import logging\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 0.25.3\n",
      "System version: 3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 15:18:16) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"System version: {}\".format(sys.version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '10m'\n",
    "\n",
    "# Model parameters\n",
    "\n",
    "# rank of the model, a positive integer (usually small), required parameter\n",
    "rank_parameter = 1\n",
    "# regularization parameter multiplied to loss function, a positive number (usually small), required parameter\n",
    "regularization_parameter = 0.5\n",
    "# initialization option for the model, 'svd' employs singular value decomposition, optional parameter\n",
    "initialization_flag = 'svd' #default is 'random'\n",
    "# maximum number of iterations for the solver, a positive integer, optional parameterj\n",
    "maximum_iteration = 500 #optional, default is 100\n",
    "# maximum time in seconds for the solver, a positive integer, optional parameter\n",
    "maximum_time = 1000#optional, default is 1000\n",
    "\n",
    "# Verbosity of the intermediate results\n",
    "verbosity=0 #optional parameter, valid values are 0,1,2, default is 0\n",
    "# Whether to compute per iteration train RMSE (and test RMSE, if test data is given)\n",
    "compute_iter_rmse=True #optional parameter, boolean value, default is False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fakedata1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6/10/2019 13:01</td>\n",
       "      <td>Cold Brew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9/6/2019 8:31</td>\n",
       "      <td>Expresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10/6/2019 13:15</td>\n",
       "      <td>Pistachios Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4/27/2019 14:43</td>\n",
       "      <td>Vanilla Chai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7/23/2019 3:50</td>\n",
       "      <td>Cashew nut Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7/24/2019 11:54</td>\n",
       "      <td>Pistachios Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4/6/2019 8:33</td>\n",
       "      <td>Expresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>105</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5/7/2019 1:21</td>\n",
       "      <td>Cashew nut Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10/3/2019 8:09</td>\n",
       "      <td>Expresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10/3/2019 8:09</td>\n",
       "      <td>Expresso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  itemID  rating        timestamp         Products\n",
       "0        102       4       3  6/10/2019 13:01        Cold Brew\n",
       "1        110       3       1    9/6/2019 8:31         Expresso\n",
       "2        100      10       1  10/6/2019 13:15  Pistachios Pack\n",
       "3        106       2       1  4/27/2019 14:43     Vanilla Chai\n",
       "4        100      11       3   7/23/2019 3:50  Cashew nut Pack\n",
       "...      ...     ...     ...              ...              ...\n",
       "996      105      10       2  7/24/2019 11:54  Pistachios Pack\n",
       "997      111       3       2    4/6/2019 8:33         Expresso\n",
       "998      105      11       1    5/7/2019 1:21  Cashew nut Pack\n",
       "999      106       3       2   10/3/2019 8:09         Expresso\n",
       "1000     106       3       2   10/3/2019 8:09         Expresso\n",
       "\n",
       "[1001 rows x 5 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If both validation and test sets are required\n",
    "# train, validation, test = python_random_split(df,[0.6, 0.2, 0.2])\n",
    "\n",
    "## If validation set is not required\n",
    "train, test = python_random_split(df,[0.8, 0.2])\n",
    "\n",
    "## If test set is not required\n",
    "# train, validation = python_random_split(df,[0.8, 0.2])\n",
    "\n",
    "## If both validation and test sets are not required (i.e., the complete dataset is for training the model)\n",
    "# train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = RLRMCdataset(train=train, validation=validation, test=test)\n",
    "data = RLRMCdataset(train=train, test=test) # No validation set\n",
    "# data = RLRMCdataset(train=train, validation=validation) # No test set\n",
    "# data = RLRMCdataset(train=train) # No validation or test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the RLRMC model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RLRMCalgorithm(rank = rank_parameter,\n",
    "                       C = regularization_parameter,\n",
    "                       model_param = data.model_param,\n",
    "                       initialize_flag = initialization_flag,\n",
    "                       maxiter=maximum_iteration,\n",
    "                       max_time=maximum_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<reco_utils.recommender.rlrmc.RLRMCalgorithm.RLRMCalgorithm at 0x211bd02ee80>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.36005282402038574 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(data,verbosity=verbosity)\n",
    "\n",
    "# fit_and_evaluate will compute RMSE on the validation set (if given) at every iteration\n",
    "# model.fit_and_evaluate(data,verbosity=verbosity)\n",
    "\n",
    "train_time = time.time() - start_time # train_time includes both model initialization and model training time. \n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Obtain predictions from the RLRMC model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain predictions on (userID,itemID) pairs (60586,54775) and (52681,36519) in Movielens 10m dataset\n",
    "# output = model.predict([60586,52681],[54775,36519]) # Movielens 10m dataset\n",
    "\n",
    "# Obtain prediction on the full test set\n",
    "predictions_ndarr = model.predict(test['userID'].values,test['itemID'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t3.916396\n",
      "MAE:\t3.127031\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(data={\"userID\": test['userID'].values, \"itemID\":test['itemID'].values, \"prediction\":predictions_ndarr})\n",
    "\n",
    "## Compute test RMSE \n",
    "eval_rmse = rmse(test, predictions_df)\n",
    "## Compute test MAE \n",
    "eval_mae = mae(test, predictions_df)\n",
    "\n",
    "print(\"RMSE:\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t%f\" % eval_mae, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying the same model with chronological split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_chrono_split(\n",
    "    df,[0.8, 0.2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = RLRMCdataset(train=train, validation=validation, test=test)\n",
    "data = RLRMCdataset(train=train, test=test) # No validation set\n",
    "# data = RLRMCdataset(train=train, validation=validation) # No test set\n",
    "# data = RLRMCdataset(train=train) # No validation or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RLRMCalgorithm(rank = rank_parameter,\n",
    "                       C = regularization_parameter,\n",
    "                       model_param = data.model_param,\n",
    "                       initialize_flag = initialization_flag,\n",
    "                       maxiter=maximum_iteration,\n",
    "                       max_time=maximum_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<reco_utils.recommender.rlrmc.RLRMCalgorithm.RLRMCalgorithm at 0x211bda1a8d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.956524133682251 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(data,verbosity=verbosity)\n",
    "\n",
    "# fit_and_evaluate will compute RMSE on the validation set (if given) at every iteration\n",
    "# model.fit_and_evaluate(data,verbosity=verbosity)\n",
    "\n",
    "train_time = time.time() - start_time # train_time includes both model initialization and model training time. \n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain predictions on (userID,itemID) pairs (60586,54775) and (52681,36519) in Movielens 10m dataset\n",
    "# output = model.predict([60586,52681],[54775,36519]) # Movielens 10m dataset\n",
    "\n",
    "# Obtain prediction on the full test set\n",
    "predictions_ndarr = model.predict(test['userID'].values,test['itemID'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t1.252853\n",
      "MAE:\t0.924643\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(data={\"userID\": test['userID'].values, \"itemID\":test['itemID'].values, \"prediction\":predictions_ndarr})\n",
    "\n",
    "## Compute test RMSE \n",
    "eval_rmse = rmse(test, predictions_df)\n",
    "## Compute test MAE \n",
    "eval_mae = mae(test, predictions_df)\n",
    "\n",
    "print(\"RMSE:\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t%f\" % eval_mae, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
